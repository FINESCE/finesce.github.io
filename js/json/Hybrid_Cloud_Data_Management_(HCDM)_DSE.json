[
    {
        "Last Update": "2015-09-08",
        "Target Usage": "",
        "Name": "Hybrid Cloud Data Management (HCDM) DSE",
        "Short Description": "",
        "Documentation": {
            "Description": "\n\n<h3>\n Basic Concepts\n</h3>\n\n<p>\n Hybrid Cloud Data Management DSE is built by the combination and integration of Object Storage GE and Identity Management Keyrock GE instances in FIWARE Lab, the local deployment of Object Storage capacities and additional encryption functionalities.\n</p>\n\n<p>\n It was originally designed to provide transparent access to the Hybrid Cloud infrastructure for the data management of the utilities within the \"Software Define Utility\" concept.  It offers with a single dashboard tool the storage management of data in two sides. Distributed machines are used to store private and very sensitive data, while the rest of the data is stored in FILAB Cloud. The identity management of all the users in order to access this data is undertaken using Identity Management Keyrock GE in FIWARE Lab.\n</p>\n\n\n<h3>\n Basic Design Principles\n</h3>\n\n<p>\n This DSE consist encompasses three main building blocks, and a unified API in order to interact with the storage system (HCDM API).\n</p>\n\n<p>\n First, through this API, users can authenticate using the IdM Keyrock, assuring a secure access to the system. The identity management module of the HCDM DSE also adds a local temporally authentication in order to speed up the subsequent accesses to the platform, and increasing the level of fault tolerance. The Storage Access module manages the access to the distributed storage system that is used as a Private Cloud (replicating data among other deployed machines), and a Public Cloud storage based on the FIWARE Lab, and the Object Storage GE instance deployed there. Finally, the replication policies are configured through the Storage Reasoning &amp; Policies module\n</p>\n\n<p>\n <img alt=\"\" src=\"images/redmine/HCDM_DSE.png\" style=\"width: 60%;\" class=img-responsive />\n</p>\n\n\n<h3>\n GE Dependancies\n</h3>\n\n<p>\n The HCDM DSE relies on Object Storage GE (v1.0.1) and IdM Keyrock GE (v4.2).\n</p>\n\n\n",
            "Copyright": "\n<p>\n Copyright \u00a9 2015 by FINESCE\n</p>\n\n\n",
            "Glossary": "\n<table class=\"themed\">\n <tr class=\"top\">\n  <td style=\"background:lightgrey;\">\n   Term\n  </td>\n  <td style=\"background:lightgrey;\">\n   Definition\n  </td>\n </tr>\n <tr>\n  <td>\n   API\n  </td>\n  <td>\n   Application Programming Interface\n  </td>\n </tr>\n <tr>\n  <td>\n   HCDM\n  </td>\n  <td>\n   Hybrid Cloud Data Management\n  </td>\n </tr>\n <tr>\n  <td>\n   DSE\n  </td>\n  <td>\n   Domain Specific Enabler\n  </td>\n </tr>\n <tr>\n  <td>\n   GE\n  </td>\n  <td>\n   Generic Enabler\n  </td>\n </tr>\n <tr>\n  <td>\n   OS\n  </td>\n  <td>\n   Object Storage\n  </td>\n </tr>\n <tr>\n  <td>\n   IdM\n  </td>\n  <td>\n   Identity Management\n  </td>\n </tr>\n <tr>\n  <td>\n   DSO\n  </td>\n  <td>\n   Distribution System Operator\n  </td>\n </tr>\n <tr>\n  <td>\n   EV\n  </td>\n  <td>\n   Electric Vehicle\n  </td>\n </tr>\n <tr>\n  <td>\n   EVSE\n  </td>\n  <td>\n   Electric Vehicle Supply Equipment\n  </td>\n </tr>\n</table>\n\n\n",
            "References": "\n\n",
            "Details": "\n<p>\n The HCDM API which is up and available to use, allows a user to access and manage data objects in the private cloud provided in the trial-site of Ireland, which is used to store historic EVSE data, or in the public cloud deployed in the FIWARE Lab. This API would open possibilities of share DSO data with other stakeholders in an easy and secure way.\n</p>\n\n<p>\n The API follows the rules of a common RESTful approach:\n</p>\n\n<ol>\n <li>\n  Rely on HTTP/RESTful services (wherever possible) in order to address the most broad community of application developers with the popular technology\n </li>\n <li>\n  Expose WP5 Stream II Future Internet in Smart Distribution Grid Communications infrastructure and trial results\n </li>\n <li>\n  Expose the HCDM DSE interface allowing the system to be accessible for external applications.\n </li>\n</ol>\n\n<p>\n <img alt=\"\" src=\"images/redmine/FINESCE_WP5_Stream_II_Trial.png\" style=\"width: 50%;\" class=img-responsive />\n</p>\n\n\n<h3>\n API Control functions\n</h3>\n\n\n\nThe following HTTP commands have been implemented being used to manipulate the data controlled by the FINESCE system.\n\t<ol>\n <li>\n  HTTP GET commands used to retrieve information or objects from the cloud platforms.\n </li>\n <li>\n  HTTP PUT commands used to create new containers in the cloud platforms or upload a new object.\n </li>\n <li>\n  HTTP DELETE commands used to delete objects or containers stored in the cloud platforms.\n </li>\n</ol>\n\n<p>\n The following services are offered in the external API. All calls require an auth_token to be sent with the request (This excludes the tokens endpoint). NOTE: the parameter for sending the authorisation token is \"auth_token\".\n</p>\n\n<p>\n #List\n <br/>\n #Create (container)\n <br/>\n #Delete\n <br/>\n #Download\n <br/>\n #Upload\n</p>\n\n\n<h3>\n Authentication process\n</h3>\n\n<p>\n In order to ensure that the user can store data in the private Cloud the authentication proxy will first validate that the user has an Object Storage application membership in IdM Keyrock. Once this validation has succeeded, then it will authenticate against Keystone. The token used for validating will be keystone\u2019s one.\n <br/>\n Different roles will be applied depending on the role on the Keyrock\u2019s application role (reseller / purchaser).\n</p>\n\n<p>\n <img alt=\"\" src=\"images/redmine/authentication.png\" style=\"width: 60%;\" class=img-responsive />\n</p>\n\n<p>\n First of all, the User sends its credentials to the AuthProxy. Then, it sends the username and password to FI-LAB\u2019s Keyrock and gets the token. With this token we can ask again to FI-LAB what applications the user has. If one of them is Object Storage we will proceed requesting a token to Keystone and then determining tenancy and get the Swift token.\n <br/>\n The token will be bundled in the response so that after this process the user knows its token. When the authentication proxy knows the token, it will store it in memcache so that for future requests (while the token is valid) it will optimize the process avoiding the validation process against FI-LAB that introduces lots of latency.\n</p>\n\n<p>\n <img alt=\"\" src=\"images/redmine/authentication_simplified.png\" style=\"width: 60%;\" class=img-responsive />\n</p>\n\n<p>\n In this case, the user sends the user + pass or the token and the resource that wants to access. The first thing that the Auth Server does is check cache if the user+pass hash matches the stored in cache. If this process success it directly can assure that the user was previously authenticated and it\u2019s not necessary to check the authentication again with FIWARE Lab.\n <br/>\n In case that no match was found in the Memcache server, it would proceed as shown in the previous figure.\n <br/>\n When working with local cache the performance is far more optimal. Supposing 50 ms round-trip delay per request, it would be around 250ms less working with cache.\n <br/>\n When authentication is done against FIWARE Lab, the token, user and pass map is stored in memcache server. There\u2019s also added an expiry field that comes as a response from the FIWARE Lab server. So the auth-proxy won\u2019t authenticate tokens that are expired. In case of an expired token, the server would return a HTTP_TIMEOUT or HTTP_UNAUTHORIZED so that the client knows that the token has expired and requests a new one.\n</p>\n\n\n<h3>\n Local instance environment deployment\n</h3>\n\n<p>\n In order to deploy a local instance of the DSE, it is needed to deploy at least one node of the distributed storage system. A guide of how to deploy new nodes and how to interconnect them is given in the following document\n <a class=\"attachment\" href=\"files/Distributed_Storage_New_Node_Deployment.doc\">\n  Distributed_Storage_New_Node_Deployment.doc\n </a>\n .\n</p>\n\n\n<h3>\n HCDM DSE front-end application\n</h3>\n\n<p>\n In order to interact with the DSE, a java-based front-end application is also offered. It uses the HCDM API in order to provide remote visual management of the private and public clod repositories. Ir provides three basic windows. First, a login window will allow the user to identify itself, starting the authentication process against the Identity Management Keyrock of the FIWARE Lab. Preferences window allows users to select the endpoint of the local and remote Object Storage proxy node and enabling SSL functionalities. Finally, the main File Manager window will allow users to create private or public (in FIWARE Lab) new folders, delete them, upload or download objects from both sites, migrate them from private to public storage and viceversa, or delete objects.\n</p>\n\n<p>\n <img alt=\"\" src=\"images/redmine/Front-end_HCDM_login.png\" style=\"width: 40%;\" class=img-responsive />\n <img alt=\"\" src=\"images/redmine/Front-end_HCDM_settings.png\" style=\"width: 40%;\" class=img-responsive />\n <img alt=\"\" src=\"images/redmine/Front-end_HCDM_manager.png\" style=\"width: 40%;\" class=img-responsive />\n</p>\n\n\n",
            "Preface": "\n<p>\n Within this document you find a self-contained open specification of the FINESCE WP5 Hybrid Cloud Data Management (HCDM) Domain Specific Enabler (DSE).\n</p>\n\n<p>\n Please consult the appropriate pages on the\n <a class=\"external\" href=\"http://www.finesce.eu/Trial_Site_Ireland.html\">\n  FINESCE\n </a>\n website in order to understand the complete context of the related FINESCE trials and this DSE.\n</p>\n\n\n",
            "ReutilisedTech": "\n<p>\n As mentioned earlier the HCDM DSE re-uses the FI-WARE Object Storage GE and Identity Management Keyrock GE.\n</p>\n\n\n"
        },
        "Version": "1.0",
        "WP": "",
        "Usage": "\n<p>\n Downloadable format:\n <a class=\"attachment\" href=\"files/Distributed_Storage_New_Node_Deployment.doc\">\n  Distributed_Storage_New_Node_Deployment.doc\n </a>\n</p>\n\n\n<h3>\n Deployment of Local Infrastructure\n</h3>\n\n<p>\n The following section describes how to deploy local infrastructure for the private distributed storage system. It explains how to deploy a multizone and multiregion Openstack Swift architecture that supports the private data.\n</p>\n\n\n<h4>\n Components:\n</h4>\n\n<p>\n 1. ESXi Image\n <br/>\n 2. vCenter Server (Optional)\n <br/>\n 3. Memcached OVA\n <br/>\n 4. FIDEV OVA\n <br/>\n 5. Storage Node OVA (Optional)\n</p>\n\n\n<h4>\n <em>\n  Step By Step\n </em>\n</h4>\n\n\n<h4>\n Configure the Virtualization Layer\n</h4>\n\n<p>\n The first step that must be performed is to install ESXi into each of the nodes that will run virtual machines.\n <br/>\n The hardware requirements of the machines are:\n</p>\n\n<p>\n -    CPU: Dual-Core 2.0GHz (&gt;=Quad Core recommended) + Intel VT Extensions\n <br/>\n -    Memory: 4GB (&gt;=8GB Recommended)\n <br/>\n -    LAN: 1x1Gb NIC or greater\n <br/>\n -    Storage (System): 2GB USB or SD Flash Drive or Any HDD/SSD\n <br/>\n -    Storage (Data): Local Storage or iSCSI/FCoE. SSD is recommended. It\u2019s recommended 1 drive per storage node that will reside on the machine.\n</p>\n\n<p>\n If the physical machines are servers, it\u2019s recommended to check the webpage of the vendor if they have any custom ESXi version for that specific platform (E.g. HP, DELL,etc.).\n <br/>\n When the installation finalizes, the next step is configure a basic NIC configuration. From the console, assign an IP address and subnet to each device. All devices should be on the same network and from another machine; all of them should answer to PING. If that is OK, we can proceed to deploy the VM.\n <br/>\n The installation of the ESXi is very lightweight and it can be done on a pen drive or SD/CF card of about 2GB of capacity.\n <br/>\n If you have a Licence to install vCenter Server, it will simplify the administration task of each node. It is recommended to use it but not compulsory.\n</p>\n\n\n<h4>\n Common Steps\n</h4>\n\n<p>\n First of all, it must be verified that each OVA has a SINGLE network interface. If it appears to have more, just delete them keeping always the first NIC!\n <br/>\n Then, a virtual switch must be created that should be mapped to the physical interface. Then connect the virtual NIC to the virtual Switch.\n <br/>\n Each VM has a password login which is:\n</p>\n\n<p>\n -    Username: openstack\n <br/>\n -    Password: F1NT3GR1S\n</p>\n\n<p>\n Also each VM has a certificate that allows root login from each machine to another. The certificate can be found at /root/.ssh/id_rsa|id_rsa.pub\n</p>\n\n<p>\n Each VM has an IP address assigned from default. It must be changed to the corresponding. In order to change it:\n</p>\n\n<p>\n -    Login as root.\n <br/>\n -    Edit the file /etc/network/interfaces.\n <br/>\n -    Set the correct parameters to Eth0 (if there is configuration for other NIC, it can be deleted).\n <br/>\n -    Save and reset the interfaces (ifdown eth0 &amp;&amp; ifup eth0).\n <br/>\n -    Verify reachability.\n</p>\n\n<p>\n Finally, the hostname of the device must be changed. To do so, edit the /etc/&lt;hostname&gt; file and set the proper name.\n <br/>\n Also, when all nodes are deployed, each node should have a copy of a /etc/hosts file with the mapping between IP and hostname of each device on the cluster. To propagate the file in an efficient way, logging in as root on one device, the file can be copied via scp command to the other nodes:\n</p>\n\n<pre>\n#scp /etc/hosts root@hostname:/etc/hosts\n</pre>\n\n\n<h4>\n Deploy the Memcached VM\n</h4>\n\n<p>\n The first machine that must be deployed is a Memcached server. It is self-contained on the OVA file. A single instance of this VM must be deployed.\n</p>\n\n<p>\n Its IP address should be replaced if it\u2019s considered to use a different IP address space. In case that the IP subnet 172.16.2.0/24 is suitable, it would better not to change it because all other machines have configured that IP address as Memcached server and it will avoid replacing it from all the other nodes.\n</p>\n\n<p>\n After replacing the system IP, it is necessary to restart the memcached service. It must also be replaced the IP address on memcached configuration. Edit the file /etc/memcached.conf and there\u2019s a line that begins with \u2013l and contains an IP address.\n</p>\n\n<p>\n Replace that with the new IP address that has been set on the machine. Save the file and restart the memcached service:\n</p>\n\n<pre>\n$sudo service memcached restart\n</pre>\n\n\n<h3>\n Decide the Architecture of Storage Nodes and Proxies\n</h3>\n\n<p>\n Before proceeding to deploy any purely storage node or FIDEV (Storage + proxy + API) it\u2019s recommended to read the following document: \"Deployment of a MultiRegion Swift\". Make special focus on the \"Single-Network Topology\" section.\n</p>\n\n<p>\n It is recommended to use the Single-Network Topology. The images are ready to be deployed that way and it is much easier and less hardware is required.\n</p>\n\n<p>\n At each Host we recommend to deploy a FIDEV and a Storage node. If there are more resources, more storage nodes can be deployed and another FIDEV can be considered.\n</p>\n\n<p>\n All VM that are deployed in the same host, they must be configured in the same zone (because if the whole node fails, all the replicas can\u2019t be in the same physical machine)\n</p>\n\n<p>\n At least a couple of Virtualization Hosts should make a region; each host on a different zone is our recommendation.\n</p>\n\n\n<h4>\n Deploy a Storage Node\n</h4>\n\n<p>\n After deploying the OVA and changing the IP address of the node and verify reachability with other nodes nothing else has to be done.\n</p>\n\n\n<h4>\n Deploy a FIDEV Node\n</h4>\n\n<p>\n After deploying the OVA and changing the IP address of the node and verify reachability there are some steps that must be performed.\n</p>\n\n<p>\n First of all, edit the file /etc/swift/proxy-server.conf\n</p>\n\n<p>\n At [filter: customauth] check the memcache server configuration set the line to:\n</p>\n\n<pre>\nmemcache_servers=@IP:11211\n</pre>\n\n<p>\n Moving down to the file, it appears the read affinity and the write affinity configuration. The read affinity must be defined in the format:\n</p>\n\n<pre>\nread_affinity = rXzY=100, rXzZ=100 ,\n</pre>\n\n<p>\n where X is the region name and Y and Z are the different zones. 100 is the priority of that region.\n</p>\n\n<p>\n The write affinity must be set in a per-region mode.\n</p>\n\n<pre>\nwrite_affinity=rX,rY\n</pre>\n\n<p>\n Below the read/write affinity configuration, there\u2019s the section [filter:cache] where the memcached server IP is set. It should be replaced with the same value used at the top of the document.\n</p>\n\n<pre>\nmemcache_servers=@IP:11211\n</pre>\n\n\n<h4>\n Create and Distribute the ring\n</h4>\n\n<p>\n Before creating the ring, please read the section \u201ccommon steps after deploying the image\u201d on the \"Deployment of a MultiRegion Swift\" document.\n</p>\n\n<p>\n Log in any node (idev or storate) and in the /etc/swift/ folder there are a couple of text files: proxies.txt and nodes.txt. Modify the values to fit the desired topology.\n</p>\n\n<p>\n When the configuration files are set, it is necessary to run the script \u2018create_ring.sh\u2019 and the ring files will be created automatically and distributed to all the nodes of the topology. It is mandatory to have the /etc/hosts file distributed to all nodes before running the script.\n</p>\n\n<p>\n The script must be run once a change to the topology is produced and must be run from a single node (do not do it to every node!)\n</p>\n\n\n<h4>\n Debugging Tips\n</h4>\n\n<p>\n After setting up the whole infrastructure it\u2019s necessary to make sure that everything works:\n</p>\n\n<p>\n - try the API: refer to the document \"Custom API Documentation\".\n <br/>\n - try the CDMI API: refer to the document \"Object Storage Encryption User Manual\" where there\u2019s a list of all capabilities and commands that can be performed against each proxy node.\n</p>\n\n\n<h4>\n Examples\n</h4>\n\n<p>\n Let us assume we want to read the files that we have stored in the Private Cloud. You can use the graphical Data Manager to check which files are stored in the Private Cloud space and which ones are in the Public Cloud. The user can drag and drop the files from one side to the other in order to migrate them from the public to private and viceversa.\n</p>\n\n<p>\n <img alt=\"\" src=\"images/redmine/Front-end_HCDM_manager.png\" style=\"width: 40%;\" class=img-responsive />\n</p>\n\n<p>\n However, DSE can also be directly accessed using the HCDM API. For example, using the List function of the HCDM API, user can obtain the names of the files stored in a specific container of the cloud. It can be done by means of any REST client such as DHC - REST/HTTP API Client configuring the List function or by using shell command \"curl --silent -X GET \"_http://$host:$portHTTP/api/list?auth=$auth&amp;token=$token&amp;container=$1_\" as further explained in\n <a class=\"attachment\" href=\"files/HCDM_API.pdf\">\n  HCDM_API.pdf\n </a>\n .\n</p>\n\n<pre>\n{\n\"items\": \n[\n\"api/\",  \n\"cdmiAPI_CONTAINER/\", \n\"cookiesSite1/\", \n\"cookiesSite2/\", \n\"cookiesSite3/\", \n\"demoBarcelona/\", \n\"demoWIT/\", \n\"demoESB/\", \n\"home/\" \n]\n}\n</pre>\n\n<p>\n On the other hand, if we want to access the Public Cloud, we can directly use the native Object Storage GE API to interact with the FIWARE Lab instance, and obtain as well an analogous response listing the files that are stored there.\n</p>\n\n\n",
        "Terms and Conditions": "\n<p>\n An instance of this SE\u2019s reference implementation runs as a part of the Irish trial and is only accessible via its API. Documentation on the API can be found at\n <a class=\"external\" href=\"https://finesce.tssg.org/documentation/index.html\">\n  https://finesce.tssg.org/documentation/index.html\n </a>\n</p>\n\n\n",
        "wiki_attachments": [
            "/redmine/attachments/download/2639/HCDM_DSE.png",
            "/redmine/attachments/download/2640/authentication_simplified.png",
            "/redmine/attachments/download/2641/authentication.png",
            "/redmine/attachments/download/2642/Distributed_Storage_New_Node_Deployment.doc",
            "/redmine/attachments/download/2643/Front-end_HCDM_login.png",
            "/redmine/attachments/download/2644/Front-end_HCDM_manager.png",
            "/redmine/attachments/download/2645/Front-end_HCDM_settings.png",
            "/redmine/attachments/download/2881/FINESCE_WP5_Stream_II_Trial.png",
            "/redmine/attachments/download/2953/HCDM_API.pdf"
        ],
        "Open Source": "",
        "Contact Person": "\n<p>\n Ramon Martin de Pozuelo\n <br/>\n FUNITEC - La Salle\n <br/>\n <a class=\"email\" href=\"mailto:ramonmdpREMOVE-NO-SPAM@salleurl.edu\">\n  ramonmdpREMOVE-NO-SPAM@salleurl.edu\n </a>\n</p>\n\n<p>\n Alan Briones\n <br/>\n FUNITEC - La Salle\n <br/>\n <a class=\"email\" href=\"mailto:abrionesREMOVE-NO-SPAM@salleurl.edu\">\n  abrionesREMOVE-NO-SPAM@salleurl.edu\n </a>\n</p>\n\n<p>\n Agust\u00edn Zaballos\n <br/>\n FUNITEC - La Salle\n <br/>\n <a class=\"email\" href=\"mailto:zaballosREMOVE-NO-SPAM@salleurl.edu\">\n  zaballosREMOVE-NO-SPAM@salleurl.edu\n </a>\n</p>\n\n\n",
        "Overview": "\n\n<h3>\n What you get\n</h3>\n\n<p>\n Hybrid Cloud Data Management is a REST service which provides to users transparent access to the Hybrid Cloud (distributed local storage or cloud storage system) infrastructure for the data management of the \"Software Define Utility\u201d, combining and integrating functionalities from Object Storage GE local instances and in FIWARE Lab; authentication through Identity Management Keyrock GE; and additional encryption functionalities.\n</p>\n\n\n<h3>\n Why to get it\n</h3>\n\n<p>\n A reference implementation of a REST service which is allows a secure management of data, privately (although allowing replication among different regions), and publicly (storing objects in FIWARE Lab through Object Storage GE).\n</p>\n\n\n<h3>\n Target Usage\n</h3>\n\n<p>\n This DSE is thought to be a data management tool for utilities (to upload public information on Electric Vehicle charging points, Smart Metering, costs of transmission system and power plants, energy costs, etc.).\n <br/>\n It could be useful for any retailer that wants a straight-forward but secure tool to manage data and share it with other stakeholders.\n</p>\n\n\n",
        "Downloads": "\n<p>\n Source code is available on GitHub:\n <a class=\"external\" href=\"https://github.com/FINESCE/HybridCloudDataManagement\">\n  HybridCloudDataManagement\n </a>\n</p>\n\n\n",
        "Instances": "\n<p>\n An instance of this DSE\u2019s reference implementation runs as a part of the trial and is not publicly accessible.\n</p>\n\n\n"
    }
]